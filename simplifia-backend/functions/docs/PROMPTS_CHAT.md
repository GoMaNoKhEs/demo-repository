# üìö Documentation des Prompts ChatAgent

**Projet** : SimplifIA - Hackathon Google Agentic AI  
**Agent** : ChatAgent (Conversation intelligente)  
**Fichier source** : `src/agents/chat.ts`  
**Date** : 24 Octobre 2025

---

## üéØ Vue d'ensemble

Le ChatAgent utilise **4 prompts principaux** pour g√©rer les conversations avec les utilisateurs et cr√©er automatiquement des processus administratifs. Chaque prompt a un r√¥le sp√©cifique et retourne des donn√©es structur√©es en JSON.

### Architecture des prompts

```
User Message
     ‚Üì
[1. analyzeContext] ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí D√©tecte changement de sujet
     ‚Üì
[2. analyzeIntentAndReadiness] ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Extrait infos + D√©tecte confirmation
     ‚Üì
[3. buildSystemPrompt] ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí D√©finit comportement global
     ‚Üì
[4. generateChatResponse] ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí G√©n√®re r√©ponse contextuelle
     ‚Üì
Agent Response
```

---

## üìù Prompt 1 : Analyse Contexte

### **M√©thode** : `analyzeContext(conversationHistory, currentMessage)`

### **Objectif**
D√©tecter si l'utilisateur change de sujet, continue la conversation, ou revient √† un sujet ant√©rieur.

### **Quand est-il appel√© ?**
- √Ä chaque nouveau message utilisateur
- Avant l'analyse d'intention
- Uniquement si historique non vide

### **Temp√©rature IA** : `0.3` (pr√©cision importante)

### **Prompt envoy√©**
```
Analyse ce contexte conversationnel :

HISTORIQUE:
user: Je veux une aide au logement APL
agent: Pour votre demande APL, pr√©cisons...
user: Je suis √©tudiant √† Paris

NOUVEAU MESSAGE:
En fait non, je veux renouveler mon passeport

D√©termine :
1. Le sujet pr√©c√©dent (ex: "Demande APL", "Renouvellement passeport", null)
2. Le sujet actuel du message
3. Si c'est un changement de sujet complet
4. Si c'est une continuit√© du sujet pr√©c√©dent
5. Si c'est un retour √† un sujet abandonn√©

Retourne UNIQUEMENT ce JSON (pas de markdown):
{
  "contextType": "continuation|topic_change|topic_return|new_conversation",
  "previousTopic": "description du sujet pr√©c√©dent ou null",
  "currentTopic": "description du sujet actuel",
  "isTopicChange": true/false,
  "shouldResetContext": true/false,
  "relevantHistory": "r√©sum√© des infos importantes √† garder"
}
```

### **Format JSON attendu**

```typescript
{
  contextType: "continuation" | "topic_change" | "topic_return" | "new_conversation",
  previousTopic: string | null,
  currentTopic: string,
  isTopicChange: boolean,
  shouldResetContext: boolean,
  relevantHistory: string
}
```

### **Exemples de r√©ponses**

#### Cas 1 : Continuation
```json
{
  "contextType": "continuation",
  "previousTopic": "Demande APL",
  "currentTopic": "Demande APL",
  "isTopicChange": false,
  "shouldResetContext": false,
  "relevantHistory": "Utilisateur √©tudiant √† Paris, locataire, revenus 800‚Ç¨"
}
```

#### Cas 2 : Changement de sujet
```json
{
  "contextType": "topic_change",
  "previousTopic": "Demande APL",
  "currentTopic": "Renouvellement passeport",
  "isTopicChange": true,
  "shouldResetContext": true,
  "relevantHistory": ""
}
```

### **Gestion d'erreurs**

```typescript
try {
  const response = await this.vertexAI.generateResponse("CHAT", prompt, { temperature: 0.3 });
  const cleanedResponse = response.replace(/```json\n?/g, "").replace(/```\n?/g, "").trim();
  return JSON.parse(cleanedResponse);
} catch (error) {
  console.error("Error analyzing context:", error);
  // Fallback : consid√©rer comme continuation
  return {
    contextType: "continuation",
    previousTopic: null,
    currentTopic: null,
    isTopicChange: false,
    shouldResetContext: false,
    relevantHistory: conversationHistory,
  };
}
```

**‚ö†Ô∏è Probl√®mes courants** :
- IA retourne markdown ‚Üí Nettoyage avec `.replace(/```json/g, "")`
- JSON invalide ‚Üí Fallback avec `contextType: "continuation"`
- Historique vide ‚Üí Retour imm√©diat `contextType: "new_conversation"`

---

## üéØ Prompt 2 : Analyse Intention et Disponibilit√©

### **M√©thode** : `analyzeIntentAndReadiness(conversationHistory, currentMessage)`

### **Objectif**
D√©terminer si l'utilisateur a fourni assez d'informations et s'il confirme vouloir cr√©er le processus administratif.

### **Quand est-il appel√© ?**
- √Ä chaque nouveau message utilisateur
- Apr√®s l'analyse de contexte
- Pour extraire les infos collect√©es

### **Temp√©rature IA** : `0.3` (pr√©cision importante)

### **Prompt envoy√©**
```
Analyse cette conversation pour d√©terminer si l'utilisateur
est pr√™t √† d√©marrer un processus administratif.

HISTORIQUE:
user: Je veux une APL
agent: Pour votre demande APL, pr√©cisons...
user: Je suis √©tudiant c√©libataire √† Paris, locataire
agent: Tr√®s bien, et vos revenus ?
user: 800‚Ç¨ par mois

NOUVEAU MESSAGE:
Oui je veux cr√©er mon dossier

Analyse et retourne UNIQUEMENT ce JSON (pas de markdown):
{
  "demarche": "nom pr√©cis de la d√©marche (ex: Demande APL, Renouvellement passeport)",
  "readyToStart": true/false,
  "userConfirmed": true/false,
  "confidence": 0.0-1.0,
  "missingInfo": ["info manquante 1", "info 2"],
  "collectedInfo": {
    "situation": "√©tudiant/salari√©/etc ou null",
    "logement": "locataire/propri√©taire ou null",
    "revenus": "montant approximatif ou null",
    "ville": "nom ville ou null"
  }
}

Crit√®res pour readyToStart = true:
- La d√©marche est clairement identifi√©e
- Au moins 2-3 infos essentielles collect√©es
- L'utilisateur semble avoir r√©pondu aux questions principales

Crit√®res pour userConfirmed = true:
- L'utilisateur confirme explicitement vouloir cr√©er le dossier
- Expressions: "oui", "d'accord", "vas-y", "lance", "je veux", etc.
- Attention aux "oui mais..." ou h√©sitations ‚Üí false
```

### **Format JSON attendu**

```typescript
{
  demarche: string,              // "Demande APL", "Renouvellement passeport"...
  readyToStart: boolean,         // A-t-on assez d'infos ?
  userConfirmed: boolean,        // Confirmation explicite ?
  confidence: number,            // 0.0 - 1.0
  missingInfo: string[],         // ["date de naissance", "num√©ro CAF"]
  collectedInfo: {
    situation?: string,          // "√©tudiant", "salari√©", "demandeur d'emploi"...
    logement?: string,           // "locataire", "propri√©taire", "h√©berg√©"...
    revenus?: string,            // "800", "1500‚Ç¨", "950 euros"...
    ville?: string,              // "Paris", "Marseille", "Lyon"...
    [key: string]: any           // Champs additionnels possibles
  }
}
```

### **Exemples de r√©ponses**

#### Cas 1 : Pr√™t et confirm√©
```json
{
  "demarche": "Demande APL",
  "readyToStart": true,
  "userConfirmed": true,
  "confidence": 0.95,
  "missingInfo": [],
  "collectedInfo": {
    "situation": "√©tudiant",
    "logement": "locataire",
    "revenus": "800‚Ç¨",
    "ville": "Paris"
  }
}
```

#### Cas 2 : Infos manquantes
```json
{
  "demarche": "Demande APL",
  "readyToStart": false,
  "userConfirmed": false,
  "confidence": 0.6,
  "missingInfo": ["revenus", "ville"],
  "collectedInfo": {
    "situation": "√©tudiant",
    "logement": "locataire",
    "revenus": null,
    "ville": null
  }
}
```

#### Cas 3 : Confirmation sans infos compl√®tes
```json
{
  "demarche": "Demande CAF",
  "readyToStart": false,
  "userConfirmed": true,
  "confidence": 0.4,
  "missingInfo": ["type d'aide exact", "situation", "revenus"],
  "collectedInfo": {
    "situation": null,
    "logement": null,
    "revenus": null,
    "ville": "Lyon"
  }
}
```

### **Seuil de confiance utilis√©**

```typescript
// Dans processUserMessage() (ligne 50)
if (intentAnalysis.readyToStart && intentAnalysis.userConfirmed && intentAnalysis.confidence > 0.7) {
  await this.createProcessFromConversation(sessionId, intentAnalysis);
  return;
}
```

**‚ö†Ô∏è Seuil de 0.7** : L'IA doit √™tre assez confiante avant de cr√©er le processus.

### **Gestion d'erreurs**

```typescript
try {
  const response = await this.vertexAI.generateResponse("CHAT", prompt, { temperature: 0.3 });
  const cleanedResponse = response.replace(/```json\n?/g, "").replace(/```\n?/g, "").trim();
  return JSON.parse(cleanedResponse);
} catch (error) {
  console.error("Error analyzing intent:", error);
  // Fallback : pas pr√™t, confidence 0
  return {
    demarche: "Inconnu",
    readyToStart: false,
    userConfirmed: false,
    confidence: 0,
    missingInfo: [],
    collectedInfo: {},
  };
}
```

**‚ö†Ô∏è Probl√®mes courants** :
- IA retourne markdown ‚Üí Nettoyage avec `.replace()`
- `confidence` en string au lieu de number ‚Üí Parser avec `parseFloat()`
- Champs manquants ‚Üí Fallback avec valeurs par d√©faut
- Expressions de confirmation non d√©tect√©es ‚Üí Ajuster le prompt

---

## ü§ñ Prompt 3 : System Prompt Principal

### **M√©thode** : `buildSystemPrompt()`

### **Objectif**
D√©finir le comportement global de SimplifIA et ses r√®gles de conversation.

### **Quand est-il utilis√© ?**
- Pass√© en `systemInstruction` √† chaque appel `generateChatResponse()`
- D√©finit la "personnalit√©" de l'agent

### **Prompt complet**

```
Tu es SimplifIA, l'expert des d√©marches administratives fran√ßaises. 
Tu es pr√©cis, m√©thodique et tu poses les bonnes questions.

R√àGLES ABSOLUES :
1. MAXIMUM 2-3 questions √† la fois (√©viter la surcharge cognitive)
2. Apr√®s 4 √©changes (8 messages total), TOUJOURS proposer de cr√©er le dossier
3. TOUJOURS poser des questions pr√©cises pour comprendre la situation exacte
4. JAMAIS de r√©ponses g√©n√©riques comme "rendez-vous sur le site" 
5. IDENTIFIER pr√©cis√©ment l'aide/d√©marche demand√©e
6. LISTER les documents exacts n√©cessaires
7. EXPLIQUER les √©tapes concr√®tes √† suivre

EXEMPLES PR√âCIS :

Pour "demande CAF" :
"Pour votre demande CAF, pr√©cisons :
Quelle aide exactement ? (RSA, APL, Prime d'activit√©, AAH, allocation familiale...)
Votre situation ? (√©tudiant, salari√©, demandeur d'emploi, parent isol√©...)
Votre logement ? (locataire, propri√©taire, h√©berg√© chez famille...)
Vos revenus mensuels approximatifs ?

Avec ces infos, je vous donnerai la liste exacte des documents et les √©tapes pr√©cises."

Pour "carte d'identit√©" :
"Pour renouveler votre CNI :
Votre commune a-t-elle un service CNI ? (pas toutes les mairies)
Premi√®re demande ou renouvellement ?
Avez-vous votre ancienne carte ou passeport ?
Voulez-vous que je v√©rifie les cr√©neaux disponibles dans votre secteur ?"

TOUJOURS finir par une question pour approfondir.
```

### **√âvolution du prompt**

| Version | R√®gles | Conformit√© ROADMAP |
|---------|--------|-------------------|
| **v1** (Initiale) | 5 r√®gles basiques | ‚ùå 75% |
| **v2** (Actuelle) | 7 r√®gles + concision | ‚úÖ 100% |

**Ajouts v2** :
- ‚úÖ R√®gle #1 : "MAXIMUM 2-3 questions √† la fois"
- ‚úÖ R√®gle #2 : "Apr√®s 4 √©changes (8 messages), TOUJOURS proposer"

### **Impact des r√®gles**

#### R√®gle 1 : Maximum 2-3 questions
**Avant** :
```
Agent: "Pour votre demande APL, j'ai besoin de plusieurs informations :
1. Quelle est votre situation professionnelle ?
2. √ätes-vous locataire ou propri√©taire ?
3. Quels sont vos revenus mensuels ?
4. Avez-vous des personnes √† charge ?
5. Depuis combien de temps habitez-vous √† cette adresse ?"
```

**Apr√®s** :
```
Agent: "Pour votre demande APL, pr√©cisons d'abord :
1. Quelle est votre situation ? (√©tudiant, salari√©, demandeur d'emploi...)
2. √ätes-vous locataire ou propri√©taire ?"
```

#### R√®gle 2 : Limite 4 √©changes (8 messages)
**Impl√©mentation** :
```typescript
// Dans processUserMessage() (ligne 57-75)
const messageCount = messagesSnapshot.size + 2;

if (messageCount >= 8 && !intentAnalysis.readyToStart) {
  const response = `‚úÖ J'ai collect√© plusieurs informations sur votre demande.

R√©sum√© :
${JSON.stringify(intentAnalysis.collectedInfo, null, 2)}

Souhaitez-vous que je cr√©e votre dossier maintenant ?
(R√©pondez "oui" pour d√©marrer)`;

  await this.addAgentResponse(sessionId, response);
  return;
}
```

---

## üí¨ Prompt 4 : G√©n√©ration R√©ponse Contextuelle

### **M√©thode** : `generateChatResponse(systemPrompt, userMessage, conversationHistory, contextAnalysis, intentAnalysis?)`

### **Objectif**
G√©n√©rer une r√©ponse adapt√©e au contexte d√©tect√© (continuation, changement de sujet, etc.).

### **Temp√©rature IA** : `0.7` (par d√©faut, non sp√©cifi√©e)

### **Instructions dynamiques selon contexte**

#### Contexte : `topic_change`
```
‚ö†Ô∏è L'utilisateur CHANGE DE SUJET.
Ancien sujet: Demande APL
Nouveau sujet: Renouvellement passeport

‚û°Ô∏è Tu dois:
1. Accuser r√©ception du changement (ex: "D'accord, parlons de Renouvellement passeport")
2. Repartir de z√©ro sur ce nouveau sujet
3. Ne pas m√©langer avec le contexte pr√©c√©dent
```

#### Contexte : `topic_return`
```
L'utilisateur REVIENT √† un sujet ant√©rieur.
Sujet retrouv√©: Demande APL

Tu dois:
1. Reconna√Ætre le retour (ex: "Ah oui, revenons √† votre Demande APL")
2. Reprendre les infos d√©j√† collect√©es: √©tudiant, locataire, Paris
3. Continuer depuis o√π vous √©tiez
```

#### Contexte : `continuation`
```
L'utilisateur CONTINUE le sujet en cours.
Sujet: Demande APL

Tu dois:
1. Prendre en compte TOUT l'historique
2. Ne PAS redemander des infos d√©j√† donn√©es
3. Progresser logiquement dans la conversation
```

#### Contexte : `new_conversation`
```
NOUVELLE CONVERSATION (pas d'historique)

Tu dois:
1. Accueillir l'utilisateur
2. Identifier sa demande
3. Commencer √† poser les bonnes questions
```

### **Prompt complet g√©n√©r√©**

```
[INSTRUCTION CONTEXTUELLE CI-DESSUS]

HISTORIQUE DE LA CONVERSATION:
user: Je veux une aide au logement
agent: Pour votre demande d'aide au logement...
user: Je suis √©tudiant √† Paris

NOUVEAU MESSAGE UTILISATEUR:
Mon loyer est de 850‚Ç¨ par mois

INSTRUCTIONS:
- R√©pondre de mani√®re pr√©cise et m√©thodique
- Adapter ta r√©ponse au contexte d√©tect√© ci-dessus
- Poser les bonnes questions pour comprendre la situation exacte
- Fournir des √©tapes concr√®tes et des informations pratiques
- Maximum 2-3 questions √† la fois

R√©ponse:
```

### **Gestion d'erreurs**

```typescript
try {
  const response = await this.vertexAI.generateResponse("CHAT", prompt, {
    systemInstruction: systemPrompt,
  });

  return response.trim() || "Je suis d√©sol√©, je n'ai pas pu g√©n√©rer une r√©ponse appropri√©e.";
} catch (error) {
  console.error("Error generating chat response:", error);
  return "Je suis d√©sol√©, j'ai rencontr√© une erreur. Pouvez-vous reformuler votre question ?";
}
```

**‚ö†Ô∏è Fallback** : Message d'erreur g√©n√©rique pour ne jamais laisser l'utilisateur sans r√©ponse.

---

## üîß Cas d'erreur communs

### Erreur 1 : JSON avec markdown
**Sympt√¥me** :
```json
```json
{
  "demarche": "Demande APL",
  ...
}
```
```

**Solution** :
```typescript
const cleanedResponse = response
  .replace(/```json\n?/g, "")
  .replace(/```\n?/g, "")
  .trim();
```

### Erreur 2 : Champs manquants dans JSON
**Sympt√¥me** :
```json
{
  "demarche": "Demande APL"
  // manque readyToStart, userConfirmed, etc.
}
```

**Solution** : Toujours v√©rifier et fournir des fallbacks
```typescript
const intentAnalysis = {
  demarche: parsed.demarche || "Inconnu",
  readyToStart: parsed.readyToStart ?? false,
  userConfirmed: parsed.userConfirmed ?? false,
  confidence: parsed.confidence ?? 0,
  missingInfo: parsed.missingInfo || [],
  collectedInfo: parsed.collectedInfo || {},
};
```

### Erreur 3 : Types incorrects
**Sympt√¥me** :
```json
{
  "confidence": "0.95"  // string au lieu de number
}
```

**Solution** : Parser les valeurs
```typescript
confidence: typeof parsed.confidence === "string" 
  ? parseFloat(parsed.confidence) 
  : parsed.confidence
```

### Erreur 4 : Quota Vertex AI d√©pass√©
**Sympt√¥me** :
```
Error: 429 RESOURCE_EXHAUSTED: Quota exceeded
```

**Solution actuelle** : Laisser l'erreur remonter
**Solution future** : Impl√©menter retry logic (voir t√¢che optionnelle)

---

## üìä M√©triques et Performance

### Temps de r√©ponse moyen

| Prompt | Dur√©e moyenne | Complexit√© |
|--------|--------------|------------|
| analyzeContext | 1-2s | Faible |
| analyzeIntentAndReadiness | 2-3s | Moyenne |
| generateChatResponse | 2-4s | √âlev√©e |
| **Total par message** | **5-9s** | - |

### Co√ªts Vertex AI (estimation)

**Mod√®le** : `gemini-2.0-flash-lite` (AI_MODELS.CHAT)

| Prompt | Tokens input | Tokens output | Co√ªt unitaire |
|--------|--------------|---------------|---------------|
| analyzeContext | ~300 | ~100 | $0.0001 |
| analyzeIntentAndReadiness | ~400 | ~150 | $0.0002 |
| generateChatResponse | ~500 | ~200 | $0.0003 |
| **Total par message** | **~1200** | **~450** | **$0.0006** |

**Pour 1000 conversations** (4 √©changes/conversation) :
- Total tokens : ~6.6M
- Co√ªt estim√© : ~$2.40

---

## üß™ Tests E2E

Tous les prompts sont test√©s dans `src/test/test-chat.ts` :

| Test | Prompts test√©s | Status |
|------|----------------|--------|
| Test 1 : Conversation compl√®te | Tous les 4 | ‚úÖ |
| Test 2 : D√©tection confirmation | analyzeIntentAndReadiness | ‚úÖ |
| Test 3 : Limite 8 messages | buildSystemPrompt | ‚úÖ |
| Test 4 : Analyse intention | analyzeIntentAndReadiness | ‚úÖ |
| Test 5 : Historique vide | generateChatResponse | ‚úÖ |
| Test 6 : Changement sujet | analyzeContext | ‚úÖ |

**Commande pour lancer les tests** :
```bash
cd simplifia-backend/functions
npm run build
node lib/test/test-chat.js
```

---

## üîÆ Am√©liorations futures

### Priorit√© HAUTE
- [ ] Ajouter retry logic pour Vertex AI (3 tentatives max)
- [ ] Valider strictement les formats JSON retourn√©s
- [ ] Logger les prompts/r√©ponses pour debugging

### Priorit√© MOYENNE
- [ ] Ajouter m√©triques (dur√©e, taux succ√®s par prompt)
- [ ] Cr√©er variants A/B du system prompt
- [ ] Optimiser les tokens (r√©duire longueur prompts)

### Priorit√© BASSE
- [ ] Support multi-langues (anglais, espagnol...)
- [ ] Personnalisation du ton selon utilisateur
- [ ] Cache des r√©ponses fr√©quentes

---

## üìñ R√©f√©rences

- **Fichier source** : `src/agents/chat.ts`
- **Tests** : `src/test/test-chat.ts`
- **Mod√®le IA** : Configuration dans `src/config/ai-models.ts`
- **ROADMAP** : `ROADMAP_HACKATHON.md` (Jour 1 - ChatAgent)

---

**Derni√®re mise √† jour** : 24 Octobre 2025  
**Auteur** : DEV1 (avec audit DEV2)  
**Version** : 2.0 (avec r√®gles concision)
